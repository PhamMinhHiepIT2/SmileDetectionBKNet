{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/admin/anaconda3/envs/py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import CNN2Head_input\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import BKNetStyle\n",
    "from const import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PREPARE DATA '''\n",
    "import sys\n",
    "sys.setrecursionlimit(150000)\n",
    "\n",
    "np_load_old = np.load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load smile image...................\n",
      "10000\n",
      "10165\n",
      "Done !\n",
      "Number of smile train data:  10000\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "# np.load = lambda *a,**k: np_load_old(*a,allow_pickle=True)\n",
    "smile_train, smile_test = CNN2Head_input.getSmileImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index, num_classes):\n",
    "    if index == 'smiling':\n",
    "        index = 1\n",
    "    elif index == 'not_smiling':\n",
    "        index = 0\n",
    "    assert index < num_classes and index >= 0\n",
    "    tmp = np.zeros(num_classes, dtype=np.float32)\n",
    "    tmp[index] = 1.0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 21:21:33.457745: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.InteractiveSession()\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/admin/anaconda3/envs/py3.8/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "x, y_, mask = BKNetStyle.Input()\n",
    "\n",
    "y_smile_conv, phase_train, keep_prob = BKNetStyle.BKNetModel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smile_loss, l2_loss, loss = BKNetStyle.selective_loss(y_smile_conv, y_, mask)\n",
    "\n",
    "\n",
    "train_step = BKNetStyle.train_op(loss, global_step)\n",
    "\n",
    "smile_mask = tf.compat.v1.get_collection('smile_mask')[0]\n",
    "\n",
    "\n",
    "y_smile = tf.compat.v1.get_collection('y_smile')[0]\n",
    "\n",
    "\n",
    "smile_correct_prediction = tf.equal(tf.argmax(y_smile_conv, 1), tf.argmax(y_smile, 1))\n",
    "\n",
    "\n",
    "smile_true_pred = tf.reduce_sum(tf.cast(smile_correct_prediction, dtype=tf.float32) * smile_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = []\n",
    "# Mask: Smile -> 0, Gender -> 1, Age -> 2\n",
    "for i in range(len(smile_train) * 10):\n",
    "    img = (smile_train[i % 3000][0] - 128) / 255.0\n",
    "    label = (smile_train[i % 3000][1])\n",
    "    train_data.append((img, one_hot(label, 4), 0.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./save/current/\n",
      "Create new model\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "Path(SAVE_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not os.path.isfile(SAVE_FOLDER + 'model.ckpt.index'):\n",
    "    print(SAVE_FOLDER)\n",
    "    print('Create new model')\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    print('OK')\n",
    "else:\n",
    "    print('Restoring existed model')\n",
    "    saver.restore(sess, SAVE_FOLDER + 'model.ckpt')\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_summary_placeholder = tf.compat.v1.placeholder(tf.float32)\n",
    "tf.compat.v1.summary.scalar('loss', loss_summary_placeholder)\n",
    "merge_summary = tf.compat.v1.summary.merge_all()\n",
    "writer = tf.compat.v1.summary.FileWriter(\"./summary/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Learning rate: 0.010000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lv/hcn20sp51tz2bc1v6l7vdn200000gn/T/ipykernel_3479/2880170445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mbatch_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         ttl, sml, l2l, _ = sess.run([loss, smile_loss, l2_loss, train_step],\n\u001b[0m\u001b[1;32m     45\u001b[0m                                               feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n\u001b[1;32m     46\u001b[0m                                                          \u001b[0mphase_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    971\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                            run_metadata)\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1378\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1364\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1454\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1455\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1456\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = tf.get_collection('learning_rate')[0]\n",
    "\n",
    "current_epoch = (int)(global_step.eval() / (len(train_data) // BATCH_SIZE))\n",
    "for epoch in range(current_epoch + 1, NUM_EPOCHS):\n",
    "    print('Epoch:', str(epoch))\n",
    "    np.random.shuffle(train_data)\n",
    "    train_img = []\n",
    "    train_label = []\n",
    "    train_mask = []\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        train_img.append(train_data[i][0])\n",
    "        train_label.append(train_data[i][1])\n",
    "        train_mask.append(train_data[i][2])\n",
    "\n",
    "    number_batch = len(train_data) // BATCH_SIZE\n",
    "\n",
    "    avg_ttl = []\n",
    "    avg_rgl = []\n",
    "    avg_smile_loss = []\n",
    "\n",
    "\n",
    "    smile_nb_true_pred = 0\n",
    "\n",
    "\n",
    "    smile_nb_train = 0\n",
    "\n",
    "\n",
    "    print(\"Learning rate: %f\" % learning_rate.eval())\n",
    "    for batch in range(number_batch):\n",
    "        top = batch * BATCH_SIZE\n",
    "        bot = min((batch + 1) * BATCH_SIZE, len(train_data))\n",
    "        batch_img = np.asarray(train_img[top:bot])\n",
    "        batch_label = np.asarray(train_label[top:bot])\n",
    "        batch_mask = np.asarray(train_mask[top:bot])\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "            if batch_mask[i] == 0.0:\n",
    "                smile_nb_train += 1\n",
    "\n",
    "        batch_img = CNN2Head_input.augmentation(batch_img, 28)\n",
    "        batch_img = np.reshape(batch_img, (-1, 28, 28, 1))\n",
    "\n",
    "        ttl, sml, l2l, _ = sess.run([loss, smile_loss, l2_loss, train_step],\n",
    "                                              feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                                                         phase_train: True,\n",
    "                                                         keep_prob: 0.5})\n",
    "\n",
    "        smile_nb_true_pred += sess.run(smile_true_pred, feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                                                                   phase_train: True,\n",
    "                                                                   keep_prob: 0.5})\n",
    "\n",
    "        avg_ttl.append(ttl)\n",
    "        avg_smile_loss.append(sml)\n",
    "\n",
    "\n",
    "        avg_rgl.append(l2l)\n",
    "\n",
    "    smile_train_accuracy = smile_nb_true_pred * 1.0 / smile_nb_train\n",
    "\n",
    "    avg_smile_loss = np.average(avg_smile_loss)\n",
    "\n",
    "\n",
    "    avg_rgl = np.average(avg_rgl)\n",
    "    avg_ttl = np.average(avg_ttl)\n",
    "\n",
    "    summary = sess.run(merge_summary, feed_dict={loss_summary_placeholder: avg_ttl})\n",
    "    writer.add_summary(summary, global_step=epoch)\n",
    "\n",
    "    print('Smile task train accuracy: ' + str(smile_train_accuracy * 100))\n",
    "\n",
    "    print('Total loss: ' + str(avg_ttl) + '. L2-loss: ' + str(avg_rgl))\n",
    "    print('Smile loss: ' + str(avg_smile_loss))\n",
    "\n",
    "\n",
    "    saver.save(sess, SAVE_FOLDER + 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
