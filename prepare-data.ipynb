{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = \"/Users/admin/Development/Dev/ComputerVision/SmileDetection/dataset/SMILEsmileD/SMILEs\"\n",
    "output = \"output\"\n",
    "# initialize the list of data and labels\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15891\n",
      "10000\n",
      "5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/py3.8/lib/python3.8/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "# loop over the input images\n",
    "for imagePath in sorted(list(paths.list_images(data_set))):\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = imutils.resize(image, width=28)\n",
    "    T = np.zeros([28, 28, 1])\n",
    "    T[:, :, 0] = image\n",
    "    # image = img_to_array(image)\n",
    "    # data.append(T)\n",
    "\n",
    "    # extract the class label from the image path and update the label list\n",
    "    label = imagePath.split(os.path.sep)[-3]\n",
    "    label = \"smiling\" if label == \"positives\" else \"not_smiling\"\n",
    "    # labels.append(label)\n",
    "    X.append((image, label))\n",
    "    \n",
    "for _ in range(10):\n",
    "    np.random.shuffle(X)\n",
    "\n",
    "print(len(X))\n",
    "\n",
    "train_data, test_data = X[:10000], X[10000:]\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "np.save('/Users/admin/Development/Dev/ComputerVision/SmileDetection/dataset/data/' + 'train.npy', train_data)\n",
    "np.save('/Users/admin/Development/Dev/ComputerVision/SmileDetection/dataset/data/' + 'test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 08:04:34.137164: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/admin/Development/Dev/ComputerVision/SmileDetection/dataset/smile'\n",
    "processed_folder = '/Users/admin/Development/Dev/ComputerVision/SmileDetection/dataset/SMILEsmileD/SMILEs/positives/positives7'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(processed_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "images_path = [os.path.join(data_path, file) for file in os.listdir(data_path)]\n",
    "for path in images_path:\n",
    "  img = cv2.imread(path)\n",
    "  result = detector.detect_faces(img)\n",
    "  if not result:\n",
    "      continue\n",
    "  face_position = result[0].get('box')\n",
    "  x = face_position[0]\n",
    "  y = face_position[1]\n",
    "  w = face_position[2]\n",
    "  h = face_position[3]\n",
    "  img = img[y:y+h, x:x+w]\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  img = cv2.resize(img, (28, 28))\n",
    "  new_image_path = os.path.join(processed_folder, os.path.basename(path))\n",
    "  cv2.imwrite(new_image_path, img)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
